/**
 * Script for spatial tracking using ARCore and WebXR API
 * @param camera - entity binded to ar-movement component
 * @param initialX - initial X axis value tracked
 * @param initialY - initial Y axis value tracked
 * @param initialZ - initial Z axis value tracked
 * @param firstMapping - indication whether the tracking happend for the 1st time
 * @param multiplier - ratio of the change of position relative to the previous value
 */
let camera, initialX, initialY, initialZ, firstMapping;
const multiplier = 2;
let bodyAvatar;
//let  constX, constY, constZ, valx, valz, valy;

/**
 * Creates and registers a new component in A-Frame
 * with name ar-movement. Upon initialization it
 * creates new ArMovement object
 */
AFRAME.registerComponent("ar-movement", {
    init: function () {
        camera = this.el;
        bodyAvatar = document.getElementById("rig");
        window.arMovement = new ArMovement();
    }
});

/**
 * A class to manage connecting to the WebXR Device API
 * and to handle spatial tracking
 */
class ArMovement {
    /**
     * A constructor binding methods and calllling
     * initialization function
     */
    constructor() {
        this.onXRFrame = this.onXRFrame.bind(this);
        this.onEnterAR = this.onEnterAR.bind(this);
        // valx = document.getElementById("valx");
        // valy = document.getElementById("valy");
        // valz = document.getElementById("valz");
        firstMapping = true;

        //let pos = camera.getAttribute("position");
        //constX = camera.object3D.position.x;
        //constY = camera.object3D.position.y;
        //constZ = camera.object3D.position.z;
        // valx.setAttribute("value", constX);
        // valy.setAttribute("value", constY);
        // valz.setAttribute("value", constZ);
        //console.log("Const X: " + constX + "Y: " + constY + "Z: " + constZ);
        this.init();
    }

    /**
     * Fetches the XRDevice, if available.
     */
    async init() {
        console.log("Starting...");
        // The entry point of the WebXR Device API is on `navigator.xr`.
        // The `XRSession` has to have `requestHitTest`,
        // indicating that the #webxr-hit-test flag is enabled.
        if (navigator.xr && XRSession.prototype.requestHitTest) {
            try {
                this.device = await navigator.xr.requestDevice();
            } catch (e) {
                // If there are no valid XRDevice's,
                // `requestDevice()` rejects the promise. Catch the
                // awaited promise and call onNoXRDevice()
                this.onNoXRDevice();
                return;
            }
        } else {
            // If `navigator.xr` or `XRSession.prototype.requestHitTest`
            // does not exist, call onNoXRDevice()
            console.log("No XRDevice found...");
            this.onNoXRDevice();
            return;
        }

        // XRDevice was found successfully. Bind a click listener
        // to the '#enter-ar' button since the spec requires calling
        // `device.requestSession()` within a user gesture.
        document
            .querySelector("#enter-ar")
            .addEventListener("click", this.onEnterAR);
    }

    /**
     * Handles a click event on the '#enter-ar' button and attempts to
     * start an XRSession.
     */
    async onEnterAR() {
        console.log("Entering AR");
        camera.setAttribute("look-controls", "enabled", "false");
        //camera.setAttribute('rotation', {x: 0, y: 0, z: 0});
        camera.object3D.matrixAutoUpdate = true;
        // Creates an XRPresentationContext
        // on a canvas element, which will be hidden.
        const outputCanvas = document.createElement("canvas");
        const ctx = outputCanvas.getContext("xrpresent");
        outputCanvas.style.visibility = "hidden";
        document.querySelector("#enter-ar").style.visibility = "hidden";
        try {
            // Requests a session for the XRDevice with the created XRPresentationContext
            // The `device.requestSession()` must be called in response to
            // a user gesture, hence this function being a click handler.
            const session = await this.device.requestSession({
                outputContext: ctx,
                environmentIntegration: true
            });
            //Adds the canvas to the body of the document
            //if `requestSession` is successful
            document.body.appendChild(outputCanvas);

            this.onSessionStarted(session);
        } catch (e) {
            alert(e.message);
            console.log("Not supported..");
            // If `requestSession` fails, the canvas is not added,
            // and onNoXRDevice() is called
            this.onNoXRDevice();
        }
    }

    /**
     * Called when spacial tracking is not supported. Renders and alert
     * and sets correct components for the head and body to be able to move
     */
    onNoXRDevice() {
        console.log("onNoXRDevice called");
        camera.setAttribute("look-controls", "enabled", "true");
        alert("Toto zariadenie nepodporuje sledovanie pozície pomocou fotoaparátu");
        // alert("The device used has no support for position tracking");
        bodyAvatar.setAttribute("movement-controls", "");
        document.querySelector("#enter-ar").style.visibility = "hidden";
    }

    /**
     * Called when the XRSession has begun. Here is the three.js
     * renderer set up and XRWebGLLayer attached to the
     * XRSession. The tracking loop is started here.
     * @param session - XRSession made in onEnterAR()
     */
    async onSessionStarted(session) {
        this.session = session;

        // Sets up the WebGLRenderer from Three.js API,
        // which handles rendering to the session's base layer.
        this.renderer = new window.AFRAME.THREE.WebGLRenderer({
            alpha: true,
            preserveDrawingBuffer: true
        });
        this.renderer.autoClear = false;

        this.gl = this.renderer.getContext();

        // Ensures that the context from the WebGLRenderer is compatible
        // with the XRDevice
        await this.gl.setCompatibleXRDevice(this.session.device);

        // Set the session's baseLayer to an XRWebGLLayer
        // using the aforementioned WebGLRenderer's context
        this.session.baseLayer = new XRWebGLLayer(this.session, this.gl);

        // Requests a frame of reference of the viewer's head.
        //The origin is the viewer's head and moves with the viewer.
        this.frameOfRef = await this.session.requestFrameOfReference("eye-level");
        this.session.requestAnimationFrame(this.onXRFrame);
    }

    /**
     * Called on the XRSession's requestAnimationFrame.
     * @param time -time in ms of each frame
     * @param frame - XRPresentationFrame of each frame
     */
    onXRFrame(time, frame) {
        let session = frame.session;
        //get a specific device's tracked
        //position and orientation (in tracking space)
        let pose = frame.getDevicePose(this.frameOfRef);

        // Queue up the next frame
        session.requestAnimationFrame(this.onXRFrame);

        //create auxiliary matrix and 3D object to store
        //position values for further processing
        var poseMatrix = new window.AFRAME.THREE.Matrix4();
        var object = new window.AFRAME.THREE.Object3D();

        //if the pose of the device was found,
        // use it to alter avatar´s body and head
        if (pose) {
            //get the elements of the found position into the matrix
            poseMatrix.elements = pose.poseModelMatrix;

            //decompose the elements and split them into position, rotation and scale
            //rotation is immediately assigned to avatar´s head,
            //position is stored for further processing

            poseMatrix.decompose(
                object.position,
                camera.object3D.rotation,
                object.scale
            );

            //in case this method is called for the 1st time and thus
            //no information about previous location is stored,
            //assign values of current position in relative space
            //to the variables and terminatethe method
            if (firstMapping) {
                // constX = bodyAvatar.object3D.position.x;
                // constY = bodyAvatar.object3D.position.y;
                // constZ = bodyAvatar.object3D.position.z;

                initialX = object.position.x;
                initialY = object.position.y;
                initialZ = object.position.z;
                firstMapping = false;

                return;
            }

            // bodyAvatar.object3D.position.x = constX + ((object.position.x - initialX) * multiplier);
            // bodyAvatar.object3D.position.y = constY + ((object.position.y - initialX) * multiplier);
            // bodyAvatar.object3D.position.z = constZ + ((object.position.z - initialX) * multiplier);
            bodyAvatar.object3D.translateX(
                (object.position.x - initialX) * multiplier
            );
            bodyAvatar.object3D.translateY(
                (object.position.y - initialY) * multiplier
            );
            bodyAvatar.object3D.translateZ(
                (object.position.z - initialZ) * multiplier
            );
            initialX = object.position.x;
            initialY = object.position.y;
            initialZ = object.position.z;
        }
    }
}
